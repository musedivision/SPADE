{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import data\n",
    "from options.test_options import TestOptions\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from util.visualizer import Visualizer\n",
    "from util import html\n",
    "from data.base_dataset import BaseDataset, get_params, get_transform\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "with open('opts.pkl', 'rb') as f:\n",
    "    opt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Muse():\n",
    "    def __init__(self):\n",
    "        self.model = Pix2PixModel(opt)\n",
    "        self.model.eval()\n",
    "\n",
    "    def post_process(self, img):\n",
    "        img = img.detach().cpu().float().numpy().squeeze()\n",
    "        image_numpy = (np.transpose(img, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "        image_numpy = np.clip(image_numpy, 0, 255)\n",
    "        return image_numpy.astype(np.uint8)\n",
    "    \n",
    "    def preprocess(self, x):\n",
    "#         params = get_params(opt, label.size)\n",
    "#         transform_label = get_transform(opt, params, method=Image.NEAREST, normalize=False)\n",
    "#         label_tensor = transform_label(label) * 255.0\n",
    "        label_tensor = torch.FloatTensor(x)[None]\n",
    "        label_tensor[label_tensor == 255] = opt.label_nc  # 'unknown' is opt.label_nc\n",
    "\n",
    "        # create one-hot label map\n",
    "        label_map = label_tensor[None].long()\n",
    "        bs, _, h, w = label_map.size()\n",
    "        nc = 184\n",
    "        \n",
    "        input_label = torch.FloatTensor(bs, nc, h, w).zero_()\n",
    "        input_semantics = input_label.scatter_(1, label_map, 1.0)\n",
    "        return input_semantics\n",
    "        \n",
    "    def infer(self, x):\n",
    "        semantics = self.preprocess(x)\n",
    "        with torch.no_grad():\n",
    "            pred = self.model.netG(semantics, z=None)\n",
    "            image_pred = self.post_process(pred)\n",
    "            return image_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = Image.open('datasets/coco_stuff/val_label/000000001490.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [SPADEGenerator] was created. Total number of parameters: 97.5 million. To see the architecture, do print(network).\n"
     ]
    }
   ],
   "source": [
    "muse = Muse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelMap_pb2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import PIL.Image as Image\n",
    "import io\n",
    "\n",
    "with open('./example_pickle_v2.pkl', 'rb') as f:\n",
    "    pb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (pb.height * pb.width) == len(pb.pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 1194)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(pb.pixel[0].internal_array\n",
    "h = pb.height\n",
    "w = pb.width\n",
    "\n",
    "labelMap = np.array(pb.pixel).reshape(h, w)\n",
    "\n",
    "labelMap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labelMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(io.BytesIO(bytearray(pb.pixel)))\n",
    "arr = np.asarray(im)\n",
    "label = arr.transpose(2,0,1)[3:].squeeze()\n",
    "label = cv2.resize(label, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.transpose(2,0,1)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_label_map(img):\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "def process_pb(pb: contact_pb2.Labelmapbuffer):\n",
    "    \"\"\" Convert Protocal buffer png\n",
    "    \"\"\"\n",
    "    im = Image.open(io.BytesIO(bytearray(pb.pixel)))\n",
    "    arr = np.asarray(im)\n",
    "    label = arr.transpose(2,0,1)[0].squeeze()\n",
    "#     print(np.unique(label))\n",
    "    label = cv2.resize(label, dsize=(256, 256))\n",
    "    return label, arr, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbs, arr, im = process_pb(pb)\n",
    "xbs = np.clip(xbs, 254,255)\n",
    "# xbs[xbs != 255] = 1. \n",
    "xbs[xbs == 254] = 64.\n",
    "xbs[xbs == 255] = 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 1668)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3983184"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patricio/code/muse/__venv__/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'post_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3fd30c6fab36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelMap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8d914029e9ae>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemantics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mimage_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_process' is not defined"
     ]
    }
   ],
   "source": [
    "yhat = muse.infer(labelMap)\n",
    "Image.fromarray(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=[256, 256], interpolation=PIL.Image.NEAREST)\n",
       "    Lambda()\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.label_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
